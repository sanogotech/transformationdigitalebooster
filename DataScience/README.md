# ğŸ“˜ Guide Pratique des 4 Types dâ€™Analyse de DonnÃ©es

*(Descriptive, Diagnostique, PrÃ©dictive, Prescriptive)*

La donnÃ©e brute ne vaut rien si elle nâ€™est pas exploitÃ©e intelligemment. Pour en tirer de la valeur, il existe **4 grands types dâ€™analyse**, qui forment une vÃ©ritable **pyramide de maturitÃ© data**.

ğŸ‘‰ Chaque Ã©tape rÃ©pond Ã  une question :

1. **Descriptive** â€“ Quoi ?
2. **Diagnostique** â€“ Pourquoi ?
3. **PrÃ©dictive** â€“ Et aprÃ¨s ?
4. **Prescriptive** â€“ Que faire ?

---

## 1ï¸âƒ£ Analyse Descriptive â€“ **â€œQue sâ€™est-il passÃ© ?â€**

### DÃ©finition

Câ€™est la **photo de la situation** : on dÃ©crit les faits observÃ©s.

### Exemples

* CA du mois : 150Kâ‚¬
* Taux de churn : 5%
* Ã‰volution des ventes sur 6 mois

### Bonnes pratiques

âœ… Standardiser les KPI (mÃªmes dÃ©finitions pour tous)
âœ… Utiliser des visualisations simples (histogrammes, courbes, camemberts)
âœ… Comparer dans le temps (MoM, YoY)
âœ… VÃ©rifier la qualitÃ© des donnÃ©es avant diffusion

### Mauvais usages

âŒ Rapporter des chiffres bruts sans contexte
âŒ Multiplier les KPI au point de noyer la direction
âŒ Produire des rapports sans action derriÃ¨re

### REX (Retour dâ€™expÃ©rience)

Une banque publiait chaque mois le volume de crÃ©dits accordÃ©s. Mais faute de comparaison avec lâ€™annÃ©e prÃ©cÃ©dente et de segmentation par rÃ©gion, elle a manquÃ© un ralentissement prÃ©occupant dans une zone clÃ©.

### Outils & MÃ©thodes

ğŸ”§ Excel / Google Sheets, SQL (SELECT, GROUP BY), Power BI, Tableau, Metabase, Python (Pandas, Matplotlib), R (ggplot2)

### Livrables

ğŸ“‘ Rapports mensuels / hebdos, Dashboards interactifs, Scorecards KPI, Data Quality Report

---

## 2ï¸âƒ£ Analyse Diagnostique â€“ **â€œPourquoi cela sâ€™est-il passÃ© ?â€**

### DÃ©finition

Câ€™est **lâ€™enquÃªte** : on cherche les **causes racines** et corrÃ©lations.

### Exemple

* Pourquoi le churn a augmentÃ© de 5% ?
  â†’ 80% des clients perdus venaient de la rÃ©gion Sud
  â†’ Ils Ã©taient majoritairement sur lâ€™offre â€œStartâ€

### Bonnes pratiques

âœ… Segmenter les donnÃ©es (par rÃ©gion, produit, profil client)
âœ… Identifier corrÃ©lations mais tester causalitÃ©
âœ… Valider les hypothÃ¨ses avec plusieurs sources
âœ… Documenter le raisonnement pour Ã©viter mauvaises interprÃ©tations

### Mauvais usages

âŒ Confondre corrÃ©lation et causalitÃ©
âŒ Se baser uniquement sur une intuition sans validation statistique
âŒ Sur-analyser au point de bloquer lâ€™action

### REX

Une startup e-commerce voyait ses ventes chuter. Lâ€™Ã©quipe marketing accusait la hausse des prix. Lâ€™analyse diagnostique a montrÃ© que 70% des abandons venaient dâ€™un **bug mobile** â†’ problÃ¨me rÃ©solu, ventes revenues.

### Outils & MÃ©thodes

ğŸ”§ SQL (jointures, cohortes), Python (scikit-learn pour corrÃ©lations), R (rÃ©gressions), Power BI/Tableau (drill-down), RCA (Root Cause Analysis), Pareto

### Livrables

ğŸ“‘ Analyse des causes racines, Diagrammes Ishikawa/Pareto, Rapports de cohortes, Documentation dâ€™investigation

---

## 3ï¸âƒ£ Analyse PrÃ©dictive â€“ **â€œQue va-t-il se passer ?â€**

### DÃ©finition

Câ€™est la **boule de cristal** : on utilise des modÃ¨les pour anticiper.

### Exemple

* Quels clients risquent de partir dans 3 mois ?
  â†’ Moins dâ€™activitÃ© sur lâ€™appli
  â†’ Revenus en baisse

### Bonnes pratiques

âœ… Commencer simple (rÃ©gression, scoring) avant ML avancÃ©
âœ… Toujours valider les modÃ¨les (train/test, cross-validation)
âœ… Mettre Ã  jour rÃ©guliÃ¨rement les modÃ¨les (drift)
âœ… Utiliser des mÃ©thodes explicables (SHAP, LIME)

### Mauvais usages

âŒ ConsidÃ©rer une prÃ©diction comme une certitude (elle reste probabiliste)
âŒ Oublier dâ€™actualiser le modÃ¨le
âŒ Lancer du ML sans donnÃ©es propres et suffisantes

### REX

Un opÃ©rateur tÃ©lÃ©com avait dÃ©ployÃ© un modÃ¨le de churn. Six mois plus tard, les prÃ©dictions sont devenues fausses car la crise avait changÃ© les comportements. Le modÃ¨le, non recalibrÃ©, a perdu toute fiabilitÃ©.

### Outils & MÃ©thodes

ğŸ”§ Python (scikit-learn, TensorFlow, PyTorch), R (caret, forecast), SQL (time series), Azure ML, AWS SageMaker, MÃ©thodes : rÃ©gression, clustering, sÃ©ries temporelles

### Livrables

ğŸ“‘ ModÃ¨les prÃ©dictifs (fichiers pickle/h5), Rapports de performance (ROC, AUC, RMSE), Tableaux de scoring, Documentation technique & mÃ©tier

---

## 4ï¸âƒ£ Analyse Prescriptive â€“ **â€œQue devons-nous faire ?â€**

### DÃ©finition

Câ€™est la **boussole** : lâ€™analyse mÃ¨ne Ã  lâ€™action concrÃ¨te.

### Exemple

* Comment rÃ©duire le churn de 20% ?
  â†’ Offres ciblÃ©es pour les clients Ã  risque
  â†’ Renforcement du service client dans le Sud

### Bonnes pratiques

âœ… DÃ©finir contraintes mÃ©tiers (budget, RH, lÃ©gales)
âœ… Tester les recommandations par A/B testing
âœ… IntÃ©grer les rÃ©sultats dans les process (CRM, ERP)
âœ… Toujours valider humainement les dÃ©cisions automatiques

### Mauvais usages

âŒ Proposer des actions impossibles Ã  appliquer (coÃ»t, RH)
âŒ NÃ©gliger lâ€™adoption par les Ã©quipes mÃ©tiers
âŒ Penser que la machine dÃ©cide seule sans validation humaine

### REX

Une banque a dÃ©ployÃ© un moteur de recommandations de crÃ©dit. Sans intÃ©grer les contraintes rÃ©glementaires, certaines propositions Ã©taient illÃ©gales â†’ perte de confiance des conseillers et retour en arriÃ¨re obligatoire.

### Outils & MÃ©thodes

ğŸ”§ Python (scipy.optimize, OR-Tools), R (lpSolve), SAS, IBM Decision Optimization, CPLEX, Gurobi, MÃ©thodes : A/B Testing, Monte Carlo, Algorithmes gÃ©nÃ©tiques

### Livrables

ğŸ“‘ Plans dâ€™action data-driven, Tableaux de recommandations, Rapports A/B Testing, IntÃ©gration CRM/ERP, Documentation mÃ©tier

---

## ğŸ¯ RÃ©sumÃ© visuel & pratique

* **Descriptive = Photo** â†’ Quoi ?
* **Diagnostique = EnquÃªte** â†’ Pourquoi ?
* **PrÃ©dictive = Boule de cristal** â†’ Et aprÃ¨s ?
* **Prescriptive = Boussole** â†’ Que faire ?

ğŸ’¡ **Le saviez-vous ?**
ğŸ‘‰ 80% des entreprises sâ€™arrÃªtent au descriptif.
ğŸ‘‰ Passer au prescriptif, câ€™est multiplier par **3 lâ€™impact business des donnÃ©es**.

---


